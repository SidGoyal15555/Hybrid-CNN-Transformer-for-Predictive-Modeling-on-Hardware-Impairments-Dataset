Technologies: Python, TensorFlow, Keras, NumPy, Matplotlib, Pandas

Project Description:

Designed and implemented a hybrid deep learning model combining 1D CNN for feature extraction and a Transformer attention mechanism for capturing temporal dependencies.

Built a regression model to predict outcomes based on time-series hardware impairment data, achieving optimized performance through dropout regularization and L2 penalty.

Handled missing values using NumPy preprocessing techniques to ensure robustness and consistency in training data.

Trained the model using mean squared error loss and evaluated performance using Mean Absolute Error (MAE) on test data.

Visualized training and validation metrics over epochs to monitor overfitting and optimize model performance.
